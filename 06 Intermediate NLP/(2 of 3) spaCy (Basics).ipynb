{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy: The Basics\n",
    "\n",
    "![https://images.newrepublic.com/bfddd1f9b55195fa1414bfc55474db6da38ed13b.jpeg?w=1000&q=65&dpi=1&fm=pjpg&h=449](https://images.newrepublic.com/bfddd1f9b55195fa1414bfc55474db6da38ed13b.jpeg?w=1000&q=65&dpi=1&fm=pjpg&h=449)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[spaCy](spacy.io) is an industrial-strength natural language processing (NLP) library for Python. spaCy's goal is to take recent advancements in natural language processing out of research papers and put them in the hands of users to build production software.\n",
    "\n",
    "spaCy handles many tasks commonly associated with building an end-to-end natural language processing pipeline:\n",
    "\n",
    "- Tokenization\n",
    "- Text normalization, such as lowercasing, stemming/lemmatization\n",
    "- Part-of-speech tagging\n",
    "- Syntactic dependency parsing\n",
    "- Sentence boundary detection\n",
    "- Named entity recognition and annotation\n",
    "\n",
    "In the \"batteries included\" Python tradition, spaCy contains built-in data and models which you can use out-of-the-box for processing general-purpose English language text:\n",
    "- Large English vocabulary, including stopword lists\n",
    "- Token \"probabilities\"\n",
    "- Word vectors\n",
    "\n",
    "spaCy is written in optimized Cython, which means it's **fast**. According to a few independent sources, it's the fastest syntactic parser available in any language. Key pieces of the spaCy parsing pipeline are written in pure C, enabling efficient multithreading (i.e., spaCy can release the *GIL*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://s3.amazonaws.com/skipgram-images/spaCy.png](https://s3.amazonaws.com/skipgram-images/spaCy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing spaCy\n",
    "\n",
    "Via **Anaconda** (https://anaconda.org/spacy/spacy):\n",
    "> `conda install -c spacy spacy`\n",
    "\n",
    "or via **pip**\n",
    "> `pip install -U spacy`\n",
    "\n",
    "And you should download the data and models from spacy, here we downlaod the English data:\n",
    "> `python -m spacy.en.download all`\n",
    "\n",
    "Note the download data is about 1Gï¼Œand it split by two parts: parser and glove word2vec modes, and you can also download them one by one:\n",
    "\n",
    "> `python -m spacy.en.download parser`\n",
    "\n",
    "> `python -m spacy.en.download glove`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.en.English at 0x10e98b0f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenize Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this's spacy tokenize test"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"this's spacy tokenize test\")\n",
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "'s\n",
      "spacy\n",
      "tokenize\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenize Test or Sentence Segmentation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this is spacy sentence tokenize test. this is second sent! is this the third sent? final test."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2 = nlp(\"this is spacy sentence tokenize test. this is second sent! is this the third sent? final test.\")\n",
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is spacy sentence tokenize test.\n",
      "this is second sent!\n",
      "is this the third sent? final test.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this is spacy lemmatize testing test. programme programming book books are more better than others. mouse mice. goose geese."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3 = nlp(\"this is spacy lemmatize testing test. programme programming book books are more better than others. mouse mice. goose geese.\")\n",
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:             this | token.lemma:      552 | token.lemma_: this\n",
      "token:               is | token.lemma:      536 | token.lemma_: be\n",
      "token:            spacy | token.lemma:   776980 | token.lemma_: spacy\n",
      "token:        lemmatize | token.lemma:   776982 | token.lemma_: lemmatize\n",
      "token:          testing | token.lemma:     4191 | token.lemma_: testing\n",
      "token:             test | token.lemma:     1877 | token.lemma_: test\n",
      "token:                . | token.lemma:      453 | token.lemma_: .\n",
      "token:        programme | token.lemma:   203054 | token.lemma_: programme\n",
      "token:      programming | token.lemma:     2171 | token.lemma_: programming\n",
      "token:             book | token.lemma:     1300 | token.lemma_: book\n",
      "token:            books | token.lemma:     1300 | token.lemma_: book\n",
      "token:              are | token.lemma:      536 | token.lemma_: be\n",
      "token:             more | token.lemma:      597 | token.lemma_: more\n",
      "token:           better | token.lemma:      761 | token.lemma_: better\n",
      "token:             than | token.lemma:      626 | token.lemma_: than\n",
      "token:           others | token.lemma:      655 | token.lemma_: other\n",
      "token:                . | token.lemma:      453 | token.lemma_: .\n",
      "token:            mouse | token.lemma:     4015 | token.lemma_: mouse\n",
      "token:             mice | token.lemma:     4015 | token.lemma_: mouse\n",
      "token:                . | token.lemma:      453 | token.lemma_: .\n",
      "token:            goose | token.lemma:   210903 | token.lemma_: goose\n",
      "token:            geese | token.lemma:   210903 | token.lemma_: goose\n",
      "token:                . | token.lemma:      453 | token.lemma_: .\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print('token: %16s | token.lemma: %8s | token.lemma_: %s' % (token, token.lemma, token.lemma_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-Speech (POS) Tagging Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is pos tagger test for spacy pos tagger"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4 = nlp(\"This is pos tagger test for spacy pos tagger\")\n",
    "doc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:             This | token.pos:       88 | token.pos_: DET\n",
      "token:               is | token.pos:       98 | token.pos_: VERB\n",
      "token:              pos | token.pos:       82 | token.pos_: ADJ\n",
      "token:           tagger | token.pos:       90 | token.pos_: NOUN\n",
      "token:             test | token.pos:       90 | token.pos_: NOUN\n",
      "token:              for | token.pos:       83 | token.pos_: ADP\n",
      "token:            spacy | token.pos:       90 | token.pos_: NOUN\n",
      "token:              pos | token.pos:       90 | token.pos_: NOUN\n",
      "token:           tagger | token.pos:       90 | token.pos_: NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print('token: %16s | token.pos: %8s | token.pos_: %s' % (token, token.pos, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognizer (NER) Test\n",
    "\n",
    "[Entity Types](https://spacy.io/docs/usage/entity-recognition#entity-types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rami Eid is studying at Stony Brook University in New York"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5 = nlp(\"Rami Eid is studying at Stony Brook University in New York\")\n",
    "doc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent:                  Rami Eid | ent.label:      377 | ent.label_: PERSON\n",
      "ent:    Stony Brook University | ent.label:      380 | ent.label_: ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in doc5.ents:\n",
    "    print('ent: %25s | ent.label: %8s | ent.label_: %s' % (ent, ent.label, ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Chunk Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Natural language processing (NLP) deals with the application of computational models to text or speech data."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6 = nlp(\"Natural language processing (NLP) deals with the application of computational models to text or speech data.\")\n",
    "doc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) deals\n",
      "the application\n",
      "computational models\n",
      "text or speech data\n"
     ]
    }
   ],
   "source": [
    "for np in doc6.noun_chunks:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apples and oranges are similar. Boots and hippos aren't."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc7 = nlp(\"Apples and oranges are similar. Boots and hippos aren't.\")\n",
    "doc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0   Apples\n",
      " 1   and\n",
      " 2   oranges\n",
      " 3   are\n",
      " 4   similar\n",
      " 5   .\n",
      " 6   Boots\n",
      " 7   and\n",
      " 8   hippos\n",
      " 9   are\n",
      "10   n't\n",
      "11   .\n"
     ]
    }
   ],
   "source": [
    "for idx, token in enumerate(doc7):\n",
    "    print('%2d   %s' % (idx, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apples = doc7[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oranges = doc7[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boots = doc7[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hippos = doc7[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hippos.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the similarity between \"apples\" and \"oranges\"\n",
    "apples.similarity(oranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the similarity between \"boots\" and \"hippos\"\n",
    "boots.similarity(hippos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Resources\n",
    "\n",
    "- [NLTK vs. spaCy: Natural Language Processing in Python](http://blog.thedataincubator.com/2016/04/nltk-vs-spacy-natural-language-processing-in-python/)\n",
    "- [More spaCy Tutorials](https://spacy.io/docs/usage/tutorials)\n",
    "- [Advanced spaCy Stuff on a Million Yelp Reviews](http://nbviewer.jupyter.org/github/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
